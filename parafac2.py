from scipy.io import loadmat
from data import irregular_tensor
import math
import torch
from tqdm import tqdm
import numpy as np

class parafac2:
    
    def __init__(self, _tensor, input_path, device):        
        # Intialization
        self.tensor = _tensor
        factor_mat = loadmat(input_path)
        _Q, self.H = factor_mat['Q'][0, :], factor_mat['H']    
        self.S, self.V = factor_mat['S'], factor_mat['V']
        self.rank = self.H.shape[0]        
        
        self.Q = np.zeros((_tensor.k, _tensor.i_max, self.rank))   # k x i_max x rank
        for _k in range(_tensor.k):
            self.Q[_k, :_tensor.i[_k], :] = _Q[_k]
                        
        # Upload to gpu        
        self.Q, self.H = torch.tensor(self.Q, device=device), torch.tensor(self.H, device=device)
        self.S, self.V = torch.tensor(self.S, device=device), torch.tensor(self.V, device=device)
        
        
    def L2_loss(self, batch_size):        
        # V * sigma * H^T
        temp_tensor = self.V.repeat(self.tensor.k, 1, 1)  # k x F x rank
        temp_tensor = temp_tensor * self.S.unsqueeze(1)   # k x F x rank
        temp_tensor = torch.matmul(temp_tensor, self.H.t())  # k x F x rank
        temp_tensor_t = torch.transpose(temp_tensor, 1, 2)
        temp_tensor = torch.matmul(temp_tensor_t, temp_tensor)  # k x rank x rank
        
        # Computing the sum of square of tensors generated by parafac2
        temp_tensor = torch.matmul(self.Q, temp_tensor)    # k x i_max x rank
        sq_sum = torch.sum(temp_tensor * self.Q)
        
        # Correct non-zero terms
        for i in tqdm(range(0, self.tensor.num_nnz, batch_size)):
            if self.tensor.num_nnz - i < batch_size:
                curr_batch_size = self.tensor.num_nnz - i
            else:
                curr_batch_size = batch_size
                
            # Prepare matrices
            _row = self.tensor.rows[i:i+curr_batch_size]
            _col = self.tensor.cols[i:i+curr_batch_size]
            _height = self.tensor.heights[i:i+curr_batch_size]
            _vals = self.tensor.vals[i:i+curr_batch_size]
            
            _Q = self.Q[_height, _row, :]  # batch size x rank
            _S = self.S[_height, :]        # batch size x rank
            _V = self.V[_col, :]           # batch size x rank
            _approx = torch.sum(torch.matmul(_Q, self.H)*_S*_V, dim=1)
            sq_sum = sq_sum - torch.sum(torch.square(_approx))
            sq_sum = sq_sum + torch.sum(torch.square(_approx - _vals))
            
        return sq_sum
    

device = torch.device("cuda:0")
_tensor = irregular_tensor('../input/23-Irregular-Tensor/cms_sample.npy', device)
_parafac2 = parafac2(_tensor, 'parafac2/cms_factor.mat', device)
print(f'fitness: {1 - math.sqrt(_parafac2.L2_loss(2^18))/math.sqrt(_tensor.sq_sum)}')            